# 鲁米-面试题（Mysql）

## 01｜数据库索引

### 什么是覆盖索引？

- 覆盖索引（Covering Index）是一种特殊类型的数据库索引，它包含了查询所需的所有列，而不仅仅是索引列本身。这种设计可以使得数据库在执行查询时，能够直接从索引中获取所需的数据，而无需再去访问实际的数据行，从而提高查询性能。

- 组合索引的方式实现

### 什么是聚簇索引 / 非聚簇索引？

- 聚簇索引

	- 定义：聚簇索引定义了数据的物理存储顺序，它决定了表中的数据是如何排列的。

	- 存储方式：聚簇索引将表的实际数据行与索引存储在一起，形成一个组织良好的数据结构。这意味着表的数据实际上是按照聚簇索引的顺序存储的。

	- 唯一性：一个表只能有一个聚簇索引，通常由主键（Primary Key）约束来创建。

	- 查询性能：由于数据行与索引存储在一起，当使用聚簇索引进行查询时，数据库可以直接访问到实际的数据行，因此查询性能通常会很高。

	- 对写操作的影响：插入、更新、删除等写操作可能会影响聚簇索引的性能，特别是在插入新数据时，可能需要调整数据的物理顺序。

- 非聚簇索引

	- 定义：非聚簇索引也会对数据进行排序，但它并不改变实际数据行的物理存储顺序。

	- 存储方式：非聚簇索引会单独存储索引的数据结构，而实际的数据行则按照表的物理存储顺序存储。

	- 唯一性：一个表可以有多个非聚簇索引。

	- 查询性能：使用非聚簇索引进行查询时，数据库首先通过索引找到对应的数据行的位置，然后再访问实际的数据。因此，相对于聚簇索引，非聚簇索引的查询可能会涉及额外的I/O操作。

	- 对写操作的影响：非聚簇索引对插入、更新、删除等写操作的影响相对较小，因为它不会改变实际数据行的物理存储顺序。

### 什么是哈希索引？MySQL InnoDB 引擎怎么创建一个哈希索引？

- 在 MySQL 中，InnoDB 存储引擎并不直接支持哈希索引。但是，MySQL 提供了一种称为"MEMORY"（也称为 HEAP）存储引擎，它支持哈希索引。

- 哈希索引（Hash Index）是一种将索引键的值通过哈希函数映射到索引表中的存储位置的索引结构。它在特定场景下可以提供非常快速的数据查找速度，但也有一些限制。

	- 主要事项

		- 哈希索引只能用于精确匹配查询，而不支持范围查询。

		- 哈希索引不支持按照索引顺序遍历整个表，因此不适合用于排序和分组操作。

		- 哈希索引对于大型表可能会占用大量内存，因此需要谨慎使用。

### 什么回表？如何避免回表？

- 回表（Lookup）是数据库中一个重要的概念，指的是当数据库引擎使用索引进行查询时，如果无法直接从索引中获取所需的数据，就需要根据索引中的指针信息再次访问表格的原始数据行。

- 方法

	- 覆盖索引

	- 合理设计索引

	- 使用索引提示

	- 适当使用聚簇索引

	- 避免不必要的 select *

	- 优化查询语句

### 树的高度和查询性能是什么关系？

### 什么是索引最左匹配原则？

- 最左匹配原则是为了确保查询时能够高效地使用索引。当查询条件涉及到复合索引的多列时，要保证查询条件从索引的最左侧列开始，并且连续使用，以确保索引可以充分发挥作用，提升查询效率。

### 范围查询、Like 之类的查询怎么影响数据库使用索引？

### 索引是不是越多越好？

- 写性能下降

- 存储空间消耗

- 查询性能下降

- 维护成本增加

- 内存占用增加

### 使用索引有什么代价？

### 如何选择合适的索引列？组合索引里面怎么确定列的顺序？状态类的列是否适合作为索引的列？

- 选择合适的索引列：

	- 平凡用户查询的列

	- 唯一性高的列

	- 经常用于连接的列

	- 范围查询的列

- 确定组合索引的列顺序：

	- 根据查询模式

	- 区分度高的列放在前面

	- 根据等值查询和范围查询的比

- 状态类的列是否适合作为索引列：

	- 经常查询的列

	- 状态是离散的

	- 是否平凡变动的

### 为什么 MySQL 使用 B+ 树作为索引的数据结构？为什么不用 B 树？为什么不用红黑树？为什么不用二叉平衡树？为什么不用跳表？

- 原因

	- 范围查询效率高

	- 适合磁盘存储

	- 减少io次数

	- 支持范围扫描

	- 适用于内存与磁盘

	- 支持高并发

- 其他数据结构

	- B树：B树也是一种常用的索引数据结构，但相对于B+树，B树的叶子节点也存储了数据，而不是只存储索引，这在磁盘存储的情况下会导致频繁的磁盘IO。

	- 红黑树、二叉平衡树：这些数据结构在内存中具有优秀的性能，但是在磁盘存储的情况下，不如B+树高效。

	- 跳表：跳表是一种有序数据结构，也可以用于实现索引，但相对于B+树来说，在实际工程应用中，B+树的实现和优化更为成熟，具有更好的稳定性和性能。

### NULL 对索引有什么影响？

- 占用额外存储空间

- 索引的null值匹配

- 范围查询

	- 忽略null

- 覆盖索引中的null

### 唯一索引是否允许多个 NULL 值？

- 可以

- 唯一索引的目的是确保索引列中的值都是唯一的，而不是限制索引列中是否可以包含NULL值。如果对一个列创建了唯一索引，那么在该列中可以包含多个NULL值，但对于非NULL值，每个值都必须是唯一的。

## 02｜SQL 优化

### 请你解释一下 EXPALIN 命令。

- 查询执行顺序

- 使用索引

- 表之间关联

- 访问类型

- 行数评估

### 你有优化过 SQL 吗？具体是怎么优化的？

- 合适的索引

- 避免使用 select *

- 谨慎使用 join

- 避免使用子查询

- 注意使用 in 和 not in

- 使用 exists 和 not exists

- 避免在索引列上函数操作

- 使用合适的数据类型

### 你有没有优化过索引？怎么优化的？

- 查看现有索引

- 分析查询模式

- 选择合适的列

- 组合索引

- 避免在索引列上进行函数操作

- 定期维护索引

- 分析查询计划

### 怎么优化 COUNT 查询？

- 使用索引

- 避免 count（*）

- 使用聚合索引

- 使用近似值

- 使用缓存

### 怎么优化 ORDER BY？

### 怎么优化 LIMIT OFFSET 查询？

### 为什么要尽量把条件写到 WHERE 而不是写到 HAVING 里面？

- 性能考虑

	- WHERE 子句可以在数据被聚合前进行过滤，因此它可以利用索引来提高查询性能。

	- 而 HAVING 子句必须在数据已经被聚合后才能进行过滤，这可能会导致性能下降。

- 语意区别

	- WHERE 子句用于过滤原始数据，它影响的是行级别的筛选。而 HAVING 子句用于筛选聚合结果，影响的是分组级别的筛选。

### 怎么给一张表添加新的索引 / 修改表结构？如果我的数据量很大呢？

- 备份

- 分析索引需求

- 在非高峰时段执行

- 添加索引

- 分阶段执行

- 查看执行效果

### USE INDEX/FORCE INDEX/IGNORE INDEX 有什么效果？

## 03｜数据库锁

### 什么是行锁、表锁？什么时候加表锁？怎么避免？

- 优化查询

- 分段处理

- 减少事务持有时间

- 使用合适的隔离级别

- 避免长事物

- 使用航锁

### 什么是乐观锁？怎么在 MySQL 里面实现一个乐观锁？

### 什么是意向锁？可以举一个例子吗？

### 什么是共享锁和排它锁？它们有什么特性？

### 什么是两阶段加锁？

- 两阶段加锁的好处在于它可以有效地避免死锁的发生。因为在第一个阶段，事务可以动态地获取锁，避免了事务之间的相互等待。在第二阶段，事务只能释放锁，不会再获取新的锁，也避免了出现循环等待的情况。

### 什么是记录锁、间隙锁和临键锁？

- 记录锁（Record Lock）：

	- 记录锁是针对表中的具体记录（行）的锁定。当一个事务对某条记录进行操作时，会对该记录进行锁定，阻止其他事务同时修改同一条记录。

- 间隙锁（Gap Lock）：

	- 间隙锁是针对一个范围（范围是指两个值之间的区间）的锁定。当一个事务在一个范围内进行查询操作时，会对这个范围的间隙进行锁定，防止其他事务在这个范围内插入新记录。

- 临键锁（Next-Key Lock）：

	- 临键锁是记录锁和间隙锁的组合，它同时锁定了某条记录和该记录前的间隙。临键锁用于保证范围查询的一致性，防止幻读（即一个事务在查询时发现了一些在其开始时不存在的记录）。

### RC 级别有间隙锁和临键锁吗？

- 不会

### MySQL 是怎么在 RR 级别下解决幻读的？

- 在 MySQL 中，Repeatable Read (RR) 隔离级别通过使用间隙锁（Gap Locks）和临键锁（Next-Key Locks）来解决幻读（Phantom Read）的问题。

### 什么情况下会加临键锁？什么情况下会加间隙锁？什么时候加记录锁？

### 唯一索引和普通索引会怎么影响锁？

- 唯一索引 设置临键锁，普通索引不会

### 你遇到过什么死锁问题吗？怎么排查的？最终又是怎么解决的？

### 你有没有优化过锁？怎么优化的？

- 选择合适的数据库隔离级别

- 尽量减少事务的范围

- 合理设计索引

- 避免长事物

- 分批处理

- 避免使用不必要的锁

- 使用乐观锁

## 04｜MVCC 协议

### 什么是 MVCC？为什么需要 MVCC？

- MVCC（Multi-Version Concurrency Control）是一种数据库并发控制的机制，它用于在多个事务同时对数据库进行读写操作时保证数据的一致性。MVCC通过版本控制来实现事务的隔离性，允许不同事务同时访问相同的数据，而不会相互干扰。

### 什么是隔离级别？隔离级别有哪几种？

- 读未提交（Read Uncommitted）：

	- 这是最低的隔离级别。在该级别下，一个事务可以读取到另一个事务尚未提交的修改。这可能导致脏读、不可重复读和幻读等问题。

- 读提交（Read Committed）：

	- 在该级别下，一个事务只能读取到另一个事务已经提交的修改。这避免了脏读，但仍然可能发生不可重复读和幻读。

- 可重复读（Repeatable Read）：

	- 在该级别下，一个事务在其生命周期内看到的数据保持一致，不受其他事务的影响。这避免了脏读和不可重复读，但仍然可能发生幻读。

- 串行化（Serializable）：

	- 这是最高的隔离级别。在该级别下，事务会被严格地顺序执行，相当于将所有的并发操作串行化执行。这可以完全避免脏读、不可重复读和幻读，但会降低并发性能。

### 什么是脏读、不可重复读、幻读？它们与隔离级别的关系是怎样的？

- 脏读（Dirty Read）：

	- 脏读发生在一个事务读取到了另一个事务尚未提交的数据时。如果这个未提交的数据发生了回滚，那么读取到的数据就是无效的。

	- 与隔离级别的关系：脏读是只发生在最低的隔离级别（读未提交）下的问题。

- 不可重复读（Non-repeatable Read）：

	- 不可重复读发生在一个事务内，相同的查询在不同时间段内返回了不同的结果。通常是由于在查询过程中，另一个事务修改了数据所导致的。

	- 与隔离级别的关系：不可重复读可能发生在低于可重复读的隔离级别下。

- 幻读（Phantom Read）：

	- 幻读发生在一个事务内，相同的查询在不同时间段内返回了不同数量的记录，通常是由于在查询过程中，另一个事务插入或删除了数据所导致的。

### 隔离级别是不是越高越好？

### 你有没有改过隔离级别？为什么改？

## 05｜数据库事务

### 什么是 undo log？为什么需要 undo log？

- undo log（回滚日志）是数据库中用于实现事务的关键组件之一。它记录了事务对数据进行的修改，以便在事务回滚或者发生错误时能够将数据恢复到之前的状态。

- 事物回滚，mvcc实现，保证事物的持久性，回滚段管理

### 什么是 redo log？为什么需要 redo log？

- redo log（重做日志）是数据库管理系统（DBMS）中用于实现事务的关键组件之一。它记录了事务对数据进行的修改，以便在数据库崩溃或者发生故障时能够将事务的修改重新执行。

- 保证事务的持久性，提高性能，恢复数据库状态，实现数据库的备份和恢复

### 什么是 binlog？它有几种模式？用来做什么？

- binlog（二进制日志）是MySQL数据库中用于记录数据库变更信息的一种日志文件，它以二进制格式记录了对数据库的所有修改操作，包括插入、更新、删除等。

- 模式

	- statement-based binlog（基于语句的二进制日志）：

		- 这种模式下，binlog 记录的是执行的 SQL 语句。当执行一个事务时，binlog 会记录执行的 SQL 语句，以及执行时的一些上下文信息。

	- row-based binlog（基于行的二进制日志）：

		- 这种模式下，binlog 记录的是每一行数据的变更情况，包括变更前后的值。相比基于语句的模式，基于行的模式提供了更为详细的记录，适用于一些复杂的情况。

- 用途

	- 数据复制

	- 数据备份和恢复

	- 数据库迁移

	- 数据审计和分析

### 事务是如何执行的？

### 什么是 ACID？隔离性和隔离级别是什么关系？你觉得哪个隔离级别满足这里的隔离性要求？

- 哪个隔离级别满足隔离性的要求取决于具体的业务场景和对数据一致性的需求。通常情况下，读提交（Read Committed）是一个合理的选择，它提供了良好的性能和一定程度的隔离性，适用于大多数应用场景。如果对数据一致性要求极高，可以考虑使用可重复读或者串行化隔离级别。

### redo log 的刷盘时机有哪些？该如何选择？你们公司用的是哪个配置？为什么用这个配置？

- 涮盘时机

	- 事务提交时：

		- 在事务提交时，MySQL会将redo log的内容刷盘到磁盘，以保证事务的持久性。

	- redo log 空间不足时：

		- 当redo log空间不足以容纳新的事务记录时，MySQL会将redo log的内容刷盘，以释放空间。

	- 定期刷盘：

		- MySQL也会定期地将redo log的内容刷盘，以保证事务的持久性。

	- MySQL关闭时：

		- 在MySQL关闭时，会将redo log的内容刷盘，以确保已提交的事务能够持久化。

- 参数

	- innodb_flush_log_at_trx_commit：1

		- 控制redo log的刷盘时机。默认值为1，表示每次事务提交时都会刷盘，保证了事务的持久性。可以设置为0或2来延迟刷盘时机，但会增加一定的风险。

	- innodb_log_buffer_size：16MB

		- 控制redo log的缓冲区大小，影响到redo log的写入频率。

	- innodb_log_file_size：48MB

		- 控制redo log文件的大小，适当调整可以减少redo log文件切换的次数，提高性能。

	- innodb_log_files_in_group：

		- 控制redo log文件组中的文件数量，可以根据实际情况进行调整。

### binlog 的刷盘时机有哪些？该如何选择？你们公司用的是哪个配置？为什么用这个配置？

- 刷盘时机

	- 事务提交时：

		- 在事务提交时，MySQL会将binlog的内容刷盘到磁盘，以保证事务的持久性。

	- 定期刷盘：

		- MySQL也会定期地将binlog的内容刷盘，以保证事务的持久性。

	- MySQL关闭时：

		- 在MySQL关闭时，会将binlog的内容刷盘，以确保已提交的事务能够持久化。

- 参数

	- sync_binlog：1

		- 控制binlog的刷盘策略。设置为1时，表示每次事务提交时都会将binlog刷盘。设置为0时，表示MySQL会根据系统情况来决定何时刷盘。

	- binlog_cache_size：32K

		- 控制binlog缓冲区的大小，影响到binlog的写入频率。

	- max_binlog_size：1GB

		- 控制单个binlog文件的最大大小，适当调整可以减少binlog文件的切换次数，提高性能。

	- binlog_format：

		- 控制binlog的格式，可以选择为ROW（基于行的格式）、STATEMENT（基于语句的格式）或MIXED（混合格式）。

### 我的事务提交了，就一定不会丢吗？怎么确保一定不会丢？

- 极端情况

	- 硬件故障

	- 数据库崩溃

	- 操作失误

### 什么是 page cache？为什么不直接写到磁盘？

- 磁盘特性

	- 磁盘I/O的高延迟：相对于内存来说，磁盘的读写速度要慢得多，因为它涉及到物理机械的动作（寻道、旋转等），这导致了磁盘I/O的高延迟。

	- 利用内存的高速度：内存的读写速度远远快于磁盘，通过将数据缓存在内存中，可以加速对数据的访问，从而提高整体性能。

	- 提高磁盘的利用率：将写入操作积累在内存中，可以批量处理，减少了对磁盘的频繁访问，从而提高了磁盘的利用率。

	- 减少对持久化存储介质的磨损：频繁地进行磁盘写入会增加磁盘的使用寿命，而通过缓存可以减少对磁盘的直接访问，降低了对存储介质的磨损。

### 在分布式环境下，当服务器告诉我写入成功的时候，一定写入成功了吗？如果服务器宕机了了可能发生什么？

- 宕机后果

	- 数据丢失：如果数据在写入成功后尚未持久化到磁盘，服务器宕机会导致数据丢失。

	- 部分写入：可能只有部分数据被写入成功，而另一部分数据由于服务器宕机而丢失。

	- 写入失败：在确认写入成功后，如果服务器宕机，实际上可能并未成功写入，这可能导致数据不一致。

- 措施

	- 持久化策略：使用适当的持久化策略，例如使用数据库事务或者采用合适的持久化存储引擎，确保数据被写入到持久化存储介质中。

	- 使用确认机制：在写入成功后，可以要求服务器返回一个确认消息，以确保数据已经成功写入。

	- 使用分布式事务：使用分布式事务管理协议，如XA协议，来确保在分布式环境下的事务一致性。

	- 实现幂等性操作：设计操作使其对同一请求的多次执行具有相同的效果，从而可以容忍重复的写入操作。

	- 实现数据复制和备份：建立数据备份和复制机制，以便在发生故障时可以快速恢复数据。

## 06｜数据迁移

### 你们单库拆分的时候是如何做数据迁移的 / 你们修改大表结构的时候是怎么做数据迁移的？怎么在保持应用不停机的情况下做数据迁移？

- 单库拆分时的数据迁移：

	- 基于主从复制：

		- 在新的目标库上部署一个从源库同步数据的实例。等待数据同步完毕后，切换应用到目标库。

	- 逐批迁移：

		- 将源库数据按照一定的规则分批次迁移到目标库，以保证每个批次的数据量可控。

	- 逻辑备份和还原：

		- 使用逻辑备份工具（如mysqldump）将源库数据导出，然后在目标库上进行还原。

	- 全量+增量备份：

		- 先进行全量备份，然后在全量备份的基础上应用增量备份，最终保证目标库的数据与源库一致。

- 修改大表结构时的数据迁移：

	- 分批次修改：

		- 将大表的修改分成多个小批次进行，每次修改一部分数据，然后等待修改完成再进行下一批次。

	- 临时表策略：

		- 创建一个临时表，将需要修改的数据复制到临时表中，然后在临时表上进行结构修改。修改完成后，再将数据迁移回原表。

	- Online DDL工具：

		- 使用支持在线DDL（数据定义语言）的工具或者框架，如pt-online-schema-change，它能在不锁表的情况下进行表结构的修改。

	- 分区表策略：

		- 如果可行的话，可以考虑将大表按照某个字段分成多个分区，然后在需要修改的分区上进行操作。

- 在保持应用不停机的情况下做数据迁移：

	- 数据库代理：

		- 使用数据库代理工具，如ProxySQL，可以在迁移过程中实现流量切换，使得应用可以无感知地切换到目标库。

	- 主从切换：

		- 在数据迁移完成后，可以将目标库提升为主库，然后将应用切换到新的主库上。

	- 负载均衡器：

		- 使用负载均衡器将应用的请求分发到源库和目标库，然后逐步将流量从源库切换到目标库。

	- 分批次迁移：

		- 将数据迁移分成多个小批次，逐步切换应用的数据源。

### 什么是双写？为什么要引入双写？

- 具体来说，双写是指在将数据写入主数据库时，同时将相同的数据写入一个或多个备份数据库或者其他持久性存储介质中。这样做的目的是为了在主数据库发生故障或者丢失数据的情况下，可以从备份中恢复数据，保证数据的持久性和可靠性。

### 如果双写的过程中，有一边写失败了，怎么办？

- 回滚整个事务

- 异步处理失败写入

- 记录失败信息

- 选择性重试

- 数据修复

### 你可以用本地事务来保证双写要么都成功，要么都失败吗？分布式事务呢？

### 为什么有一个阶段是双写，但是以目标表为准？干嘛不直接切换到单写目标表？

- 防止数据丢失

- 保证切换的原子性性

- 运行灵活的切换

- 避免终端服务

### 你们有什么容错方案？比如说如果在迁移过程中出错了，你们的应用会怎么办？

### 你们是怎么校验数据的？

- 对比源表和目标表：

- 校验数据行数：

- 比对数据摘要或哈希值：

- 随机抽样

- 使用校验工具

- 对比业务指标

### 增量数据校验你们是怎么做的？

### 数据迁移你能够做到数据绝对不出错吗？

### 如果数据出错了你们怎么修复？怎么避免并发问题？

### 让你迁移一个 2000 万行的表，你的方案大概要多久？

### 你用过 mysqldump/XtraBackup 吗？它有什么缺点？

## 07｜分库分表主键生成

### 你们分库分表怎么生成主键的？

- 单库自增主键：

	- 每个分库内部都使用自增的方式生成主键，确保每个库内的主键唯一。这种方式简单高效，但会导致跨库查询时主键不具备全局唯一性。

- 数据库范围内的唯一主键：

	- 每个分库内部使用自增或其他方式生成主键，但通过分库的编号来区分主键的范围，从而保证了整个数据库中的主键的全局唯一性。

- UUID或GUID：

	- 使用UUID或者GUID作为主键，保证了主键的全局唯一性，但会占用更多的存储空间。

- Snowflake算法：

	- Snowflake是Twitter开源的一个分布式唯一ID生成算法，可以在分布式环境中生成唯一的ID。

- 数据库序列：

	- 一些数据库支持序列（Sequence）对象，可以用来生成唯一的递增或递减数字，确保主键的唯一性。

- 分布式ID生成器：

	- 使用专门的分布式ID生成器，如美团的Leaf或者百度的UidGenerator等。

- 自定义主键生成器：

	- 根据业务需求，可以开发自定义的主键生成器，利用一些特定的规则来生成主键。

### 使用 UUID/ 数据库自增 / 雪花算法有什么优缺点？

- UUID（通用唯一标识符）

	- 优点：

		- 全局唯一性：UUID是基于时间戳、机器信息、随机数等信息生成的，理论上具有全局唯一性。

		- 无需数据库访问：UUID的生成不依赖于数据库，可以在应用层生成，不需要访问数据库就能获得唯一标识符。

	- 缺点：

		- 存储空间占用较大：UUID通常是一个128位的字符串，相比于整型自增主键，占用更多的存储空间。

		- 查询效率低：UUID是随机生成的，不利于数据库的索引和查询效率。

		- 不适合作为聚簇索引：UUID作为主键时，会导致数据在磁盘上的存储不是顺序的，容易产生随机IO，不适合作为聚簇索引。

- 数据库自增主键

	- 优点：

		- 存储空间占用小：通常是一个整型值，存储空间较小。

		- 查询效率高：自增主键是按顺序生成的，适合作为索引，提高了数据库的查询效率。

		- 适合作为聚簇索引：数据在磁盘上存储是顺序的，适合作为聚簇索引。

	- 缺点：

		- 不具备全局唯一性：只在单个表内具有唯一性，不适合作为全局唯一标识符。

- 雪花算法

	- 优点：

		- 全局唯一性：雪花算法可以在分布式环境中生成全局唯一的ID。

		- 适合分布式系统：适用于需要在分布式系统中生成唯一ID的场景。

		- ID生成效率高：雪花算法生成ID的效率很高。

	- 缺点：

		- 对系统时钟要求较高：雪花算法依赖于机器的时钟，如果时钟不同步或者发生回拨，可能会产生重复的ID。

		- 存储空间：雪花算法生成的ID是64位的整型，相比于32位整型存储空间稍大。

### 雪花算法是如何实现的？

- 核心部分

	- 时间戳部分（41位）：记录生成ID的时间，精确到毫秒级别，可以使用约69年。

	- 机器ID部分（10位）：标识生成ID的机器，可以部署在1024台机器上。

	- 序列号部分（12位）：在同一毫秒内，可以生成4096个不同的ID。

### 雪花算法是怎么做到全局唯一的？

### 怎么解决雪花算法的序列号耗尽问题?

### 怎么解决雪花算法的数据堆积问题？

### 你有没有优化过主键生成的性能？怎么优化的？效果如何？

### 你的主键生成的 ID 是严格递增的吗？不是递增有什么问题？

### 为什么我们一般使用自增主键？

### 什么是页分裂？有什么缺点？

## 08｜分库分表分页查询

### 你们公司是怎么解决分页查询的？平均查询性能如何？

### 为什么分页查询那么慢？

### 全局查询有什么优缺点？对于一个查询 LIMIT X OFFSET Y 来说，如果我命中了三张表，会取来多少数据

### 怎么提高分页查询的速度？

### 什么是二次查询？它的步骤是什么样的？

### 怎么在二次查询里面计算全局的偏移量？

### 二次查询有什么优缺点？

### 代理形态的分库分表中间件有什么优缺点？怎么解决或者改进它的缺点？

- 代理形态的分库分表中间件是一种常用于处理数据库水平扩展的工具，它通常将应用程序和底层数据库隔离，通过中间件来处理分库分表的逻辑。

### 使用中间表来进行分库分表，有什么优缺点？怎么设计中间表？

### 在使用中间表的时候，你怎么保证数据一致性？你能保证强一致吗？如果不能，不一致的时间最差是多久？

### 你们公司有没有考虑使用别的中间件来解决分页查询？你选择哪一个？为什么

## 09｜分库分表事务

### 你们公司在分库分表之后，如何解决事务问题？

- 分布式事务管理器：

	- 使用分布式事务管理器（如Seata、TCC等）来实现跨多个数据库的事务管理。这些管理器提供了事务的分阶段提交、回滚等功能，确保事务的一致性。

- 业务逻辑拆分：

	- 将业务逻辑重新设计，避免或减少跨多个数据库的事务操作。尽量将事务操作局限在单个数据库内部。

- 补偿机制：

	- 设计一套补偿机制，用于处理在分布式事务中可能出现的异常情况。例如，在一个事务中的某个环节出现问题时，可以通过补偿操作来修复数据。

- 幂等性设计：

	- 保证操作的幂等性，即使某个操作被重复执行多次，结果也是一致的。这可以通过在数据库中增加版本号或者使用唯一标识符来实现。

- 消息队列：

	- 使用消息队列作为解耦工具，将事务操作拆分成独立的消息，并在各个数据库中执行相应的操作。如果某个数据库操作失败，可以通过重新消费消息来保证事务的完成。

- 最终一致性：

	- 在一些业务场景下，可以放宽对事务一致性的要求，采用最终一致性方案来处理跨库事务。

- 回滚策略：

	- 设计合适的回滚策略，当事务中的某一环节失败时，能够及时地回滚到之前的状态。

- 分片键设计：

	- 合理选择分片键，使得事务操作的数据尽可能在同一数据库中，减少跨库事务的发生。

### 什么是两阶段提交协议？有什么缺点？

### 什么是三阶段提交协议？相比两阶段，改进点在哪里？

### 什么是 XA 事务？

- XA（eXtended Architecture）事务是一种分布式事务协议，它允许多个资源（如数据库、消息队列等）参与到同一个事务中，保证这些资源的操作要么全部成功，要么全部回滚

- XA事务的特点包括

	- 分布式事务：XA事务可以跨多个资源管理器，保证所有资源的一致性。

	- 两阶段提交：XA事务采用了两阶段提交协议来保证所有资源要么全部提交，要么全部回滚。

	- ACID特性：XA事务保证了事务的原子性、一致性、隔离性和持久性。

	- 需要支持XA接口的资源管理器：参与到XA事务中的资源管理器需要实现XA接口，以便与事务管理器进行通信。

### 你觉得 XA 事务是否满足 ACID？为什么？

### 什么是 TCC？

- TCC（Try-Confirm-Cancel）是一种分布式事务处理模式，它通过将事务拆分为三个阶段（尝试、确认、取消）来保证分布式环境下的事务一致性。

- TCC模式的基本思想是将一个大事务拆解成多个小事务，并为每个小事务设计相应的确认和取消操作，从而保证整体事务的一致性。

### 什么是 SAGA？

- SAGA 是一种用于管理长时间运行的分布式事务的模式，它采用了一种逐步迭代的方式来处理事务操作。SAGA模式的核心思想是将一个大事务拆分为一系列小事务，每个小事务都有自己的确认和补偿操作，以实现分布式事务的最终一致性。

### 什么是 AT 事务？

- AT（Atomic Transaction）事务是一种原子性事务，它是传统的单一数据库中使用的事务模型。在AT事务中，要么所有操作都成功，要么所有操作都失败，保证了一组操作的原子性。

### 什么是延迟事务？延迟事务失败了怎么办？为什么分库分表中间件喜欢用延迟事务？

### 你们公司是否允许跨库事务？为什么？有什么场景是必须要使用跨库事务的？

## 10｜分库分表无分库分表键查询

### 你们公司的分库分表是怎么分的？一般情况下怎么选择分库分表键？

### 假设说现在我的订单表是按照买家 ID 来分库分表的，现在我卖家要查询，怎么办？

### 利用中间表来支持无分库分表键查询的时候，怎么设计中间表？

### 为什么在买家分库分表的时候，按照 4832，但是同样的数据，按照卖家分库分表的时候，就只需要按照 2816？

- 买家和卖家数据量差异：买家和卖家的数据量可能不同，如果卖家数据量相对较小，按照 2816 的策略就可以满足需求。

- 访问模式不同：买家和卖家的访问模式可能不同，例如，买家的访问模式可能更密集，需要更多的库和表来支持高并发访问。

- 业务需求不同：买家和卖家可能有不同的业务需求，需要不同的分库分表策略来满足业务场景的要求。

### 广播有什么缺点？

### 可以使用什么中间件来支持复杂查询？你们公司用了什么？

## 11｜分库分表容量预估

### 你是怎么估计容量的？考虑了什么因素？

- 业务数据量

- 数据访问模式

- 存储引擎选择

- 硬件配置

- 分片策略，分片数量

- 容量预留

- 性能测试，监控运维

### 你怎么知道数据未来增长会有多快？

### 你这容量是预估了几年的数据量？为什么？

### 你是怎么利用流量录制和重放来验证数据的？

### 在流量录制之后，重放之前，如果数据修改了，你的数据校验还能正常运行吗？

### 你公司用的是 HTTPS 协议吗？使用 HTTPS 协议你怎么录制流量？

### 为什么大家都喜欢用 2 的幂来作为容量？

### 怎么扩容？有哪些步骤？

### 如果你发现之前分库分表分太多了，能不能缩容？假如要你缩容，你怎么办？

## 12｜数据库综合应用

### 你们有没有做过数据库优化？有没有做过 InnoDB 引擎优化？

### 你调过什么数据库相关的参数？为什么要调？

### InnoDB 引擎的 buffer pool 是拿来做什么的？怎么优化它的性能？

- InnoDB引擎的buffer pool是一个重要的内存区域，用于缓存数据库表和索引的数据。它的作用是加速对数据库的访问，减少磁盘I/O操作，提高数据库的性能。

### buffer pool 是不是越大越好？过大或者过小都有什么问题？怎么确定合适的大小？

### 数据库里面有很多刷盘相关的参数，你都了解吗？调过吗？根据什么来调？

### 你有没有做过主从分离？主从延迟是什么？怎么解决主从延迟？

### 你们公司的数据库主节点宕机了会发生什么？

### 什么是查询缓存？你们公司有没有用查询缓存？

